# 一、工具
- [时间戳转换](https://tool.lu/timestamp/)
- [进制转换](https://www.bchrt.com/tools/hex-calculator/)
- [json解析及格式化](https://www.json.cn/jsononline/)
- [xml解析及格式化](https://tool.ip138.com/xml/?eqid=8414d17c0001387700000004647ec545)
- [word/ppt高亮](https://word.wd1x.com/)
- [gpt 翻译](https://academic.chatwithpaper.org/)
# 二、AI
## 2.1 基础
- [机器学习笔记](http://www.ai-start.com/ml2014/)
- [深度学习笔记](http://www.ai-start.com/dl2017/)
- [llm-action](https://github.com/liguodongiot/llm-action)
- [Hands-On-LLM](https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN)
- [AI-fundermentals](https://github.com/ForceInjection/AI-fundermentals)
- [apachecn](https://github.com/apachecn)
- [ml-engineering](https://github.com/stas00/ml-engineering)
## 2.2 LLM 量化
- [深度解析LMDeploy：从KV Cache到W4A16量化技术的应用](https://zhuanlan.zhihu.com/p/15293097633)
- [深度解析Qwen-2.5-VL-7B-Instruct量化](https://zhuanlan.zhihu.com/p/1924793903082611205)
- [LLM-Quantization](https://github.com/taishan1994/LLM-Quantization)
- [大模型经典PTQ量化方法总结](https://zhuanlan.zhihu.com/p/704280420)
## 2.3 AI Infer
- [lmdeploy](https://lmdeploy.readthedocs.io/zh-cn/latest/)
- [vllm](https://docs.vllm.ai/en/latest/)
- [hf-mirror](https://hf-mirror.com/)
- [A White Paper on Neural Network Deployment](https://deployment.gitbook.io/love)

## 2.4 atention
- [I made a transformer by hand](https://vgel.me/posts/handmade-transformer/)
- [illustrated-transformer](https://jalammar.github.io/illustrated-transformer/)
- [从Online-Softmax到FlashAttention V1/V2/V3](https://zhuanlan.zhihu.com/p/668888063)
- [From Online Softmax to FlashAttention](https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf)

# 三、NVIDIA
- [how-to-optim-algorithm-in-cuda](https://github.com/BBuf/how-to-optim-algorithm-in-cuda)
- [How_to_optimize_in_GPU](https://github.com/Liu-xiandong/How_to_optimize_in_GPU)
- [LeetCUDA](https://github.com/xlite-dev/LeetCUDA)
- [快速入门Nsys/TorchProfiler/NCU](https://zhuanlan.zhihu.com/p/1945304372545291742?share_code=1b0LpgaljKZE8&utm_psn=1946268423987373429)
- [Writing Speed-of-Light Flash Attention for 5090 in CUDA C++](https://gau-nernst.github.io/fa-5090/)
- [Profiler](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof-overview)
- [nsight-system](https://docs.nvidia.com/nsight-systems/index.html)
- [在GPU Kernel中构建类eBPF风格的性能探针](https://mp.weixin.qq.com/s/FWeqR5ADU7RU7ZASkmtnTw)
- [关于拉取nvidia官方镜像所有支持的镜像名称+cuda版本-官方定时更新](https://www.cnblogs.com/chentiao/p/17408994.html)
# 四、Linux
- [Systrace for Linux-使用 systrace 分析 linux & android 的调度问题]( https://zhuanlan.zhihu.com/p/362608535)
- [linux-performance-analysis](https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55)
- [perfetto](https://perfetto.dev/docs/)
- [CentOS中升级gcc/g++](https://blog.csdn.net/Xminyang/article/details/123847056)
- [ConvertX](https://github.com/C4illin/ConvertX)
- [CentOS 7 "CXXABI_1.3.8" not found 错误解决](https://zhuanlan.zhihu.com/p/589694788)

- [awesome-hpp](https://github.com/p-ranav/awesome-hpp)
- [C++性能优化——无锁队列的原理与实现](https://zhuanlan.zhihu.com/p/678154776)
- [compiler explorer](https://godbolt.org/)
- [modern-cpp-features](https://github.com/AnthonyCalandra/modern-cpp-features/tree/master)
- [C++ shell](https://cpp.sh/)
- [awesome-cs-course](https://github.com/cubxxw/awesome-cs-course/tree/master)
- [求C++性能优化相关资料推荐](https://www.zhihu.com/question/486847589/answer/1925001370940990828?share_code=ORr56VFAiOcZ&utm_psn=1926913688641709082)
- [求C++性能优化相关资料推荐](https://www.zhihu.com/question/486847589/answer/1925166342476133406?share_code=1cGZ3q3ZaKJnp&utm_psn=1929123612767547527)
- [profile](https://www.zhihu.com/question/642449547/answer/1917617977567733289?share_code=E8Aq6LXi1FnU&utm_psn=1922407118734066317)
- [CppCon](https://github.com/CppCon)
- [TMA_自顶向下的CPU架构性能瓶颈分析](https://zhuanlan.zhihu.com/p/60569271)
# 五、leetcode
[大家都是如何刷 LeetCode 的](https://www.zhihu.com/question/280279208/answer/1935976883125720461?share_code=zsaBSTEjRFJu&utm_psn=1936098449679422666)